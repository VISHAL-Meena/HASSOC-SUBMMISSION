{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KrGaWOLRlgQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import re\n",
        "import json\n",
        "import sys\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "#import stemmer as hindi_stemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Agu3XGB2p79e",
        "outputId": "f1fa1262-7752-4c36-aed7-7d256df10714"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9RZm0Y2efdU"
      },
      "outputs": [],
      "source": [
        "english_stopwords = stopwords.words(\"english\")\n",
        "\n",
        "with open('final_stopwords.txt', encoding='utf-8') as f:\n",
        "    hindi_stopwords = f.readlines()\n",
        "    for i in range(len(hindi_stopwords)):\n",
        "        hindi_stopwords[i] = re.sub('\\n', '', hindi_stopwords[i])\n",
        "\n",
        "stopword = english_stopwords + hindi_stopwords\n",
        "english_stemmer = SnowballStemmer(\"english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "words_dict  = { \"तैराक\":\"तैर\",\n",
        "                \"चालाक\":\"चाल\",\n",
        "                \"कूलाक\":\"कूल\",\n",
        "                \"बेलन\":\"बेल\",\n",
        "                \"मिलाप\":\"मिल\",\n",
        "                \"चुपचाप\": \"चुप\",\n",
        "                \"निकास\":\"निकस\",\n",
        "                \"लुकास\":\"लुक\",\n",
        "                }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PBqvF7OcSQZR",
        "outputId": "878fb1c6-1788-4fb8-8169-f6f8fea36e13"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"MOLD_train.csv\")\n",
        "df = pd.read_csv(\"MOLD_test.csv\")\n",
        "df = df.rename(columns={'subtask_a': 'labels1','subtask_b': 'labels2','subtask_c': 'labels3','tweet': 'text'})\n",
        "df1 = df[['text', 'labels1']]\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df2 = df[['text','labels2']].dropna()\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df3 = df[['text','labels3']].dropna()\n",
        "df3.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2zQejen_TIpz",
        "outputId": "9275590a-6b6d-4471-e1a7-b686b4e7769e"
      },
      "outputs": [],
      "source": [
        "df_text1 = df1[df1['text'].notna()]\n",
        "df_text2 = df2[df2['text'].notna()]\n",
        "df_text3 = df3[df3['text'].notna()]\n",
        "df_text1 = df1.reset_index()\n",
        "df_text2 = df2.reset_index()\n",
        "df_text3 = df3.reset_index()\n",
        "df_text3.tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YAp6U1OgBHW",
        "outputId": "c57a410b-edc2-4998-ee02-9f4ad059b2a1"
      },
      "outputs": [],
      "source": [
        "df1.loc[df1['labels1'] == 'NONE'] = 'not offensive'\n",
        "df1['labels1'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0x33ItB8TQSG",
        "outputId": "3d560f60-101f-4f82-9009-5c0ef098bf55"
      },
      "outputs": [],
      "source": [
        "df2.loc[df2['labels2'] == 'NONE'] = 'TIN'\n",
        "df2['labels2'].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKXo22G7TSHy",
        "outputId": "1d08b149-f6cd-41bf-b71a-2fe9ae25a175"
      },
      "outputs": [],
      "source": [
        "df3.loc[df3['labels3'] == 'NONE'] = 'IND'\n",
        "df3['labels3'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSJUxNh_T44H"
      },
      "outputs": [],
      "source": [
        "tweets = df_text1.text\n",
        "y = df_text1.labels1\n",
        "\n",
        "#tweets = df_text2.text\n",
        "#y = df_text2.labels2\n",
        "\n",
        "#tweets = df_text3.text\n",
        "#y = df_text3.labels3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Jep8PBlUBj5"
      },
      "outputs": [],
      "source": [
        "suffixes = {\n",
        "\t    1: [\"ो\", \"े\", \"ू\", \"ु\", \"ी\", \"ि\", \"ा\"],  \n",
        "            2: [\"तृ\",\"ान\",\"ैत\",\"ने\",\"ाऊ\",\"ाव\",\"कर\", \"ाओ\", \"िए\", \"ाई\", \"ाए\", \"नी\", \"ना\", \"ते\", \"ीं\", \"ती\",\n",
        "                \"ता\", \"ाँ\", \"ां\", \"ों\", \"ें\",\"ीय\", \"ति\",\"या\", \"पन\", \"पा\",\"ित\",\"ीन\",\"लु\",\"यत\",\"वट\",\"लू\"],     \n",
        "            3: [\"ेरा\",\"त्व\",\"नीय\",\"ौनी\",\"ौवल\",\"ौती\",\"ौता\",\"ापा\",\"वास\",\"हास\",\"काल\",\"पान\",\"न्त\",\"ौना\",\"सार\",\"पोश\",\"नाक\",\n",
        "                \"ियल\",\"ैया\", \"ौटी\",\"ावा\",\"ाहट\",\"िया\",\"हार\", \"ाकर\", \"ाइए\", \"ाईं\", \"ाया\", \"ेगी\", \"वान\", \"बीन\",\n",
        "                \"ेगा\", \"ोगी\", \"ोगे\", \"ाने\", \"ाना\", \"ाते\", \"ाती\", \"ाता\", \"तीं\", \"ाओं\", \"ाएं\", \"ुओं\", \"ुएं\", \"ुआं\",\"कला\",\"िमा\",\"कार\",\n",
        "                \"गार\", \"दान\",\"खोर\"],     \n",
        "            4: [\"ावास\",\"कलाप\",\"हारा\",\"तव्य\",\"वैया\", \"वाला\", \"ाएगी\", \"ाएगा\", \"ाओगी\", \"ाओगे\", \n",
        "                \"एंगी\", \"ेंगी\", \"एंगे\", \"ेंगे\", \"ूंगी\", \"ूंगा\", \"ातीं\", \"नाओं\", \"नाएं\", \"ताओं\", \"ताएं\", \"ियाँ\", \"ियों\", \"ियां\",\n",
        "                \"त्वा\",\"तव्य\",\"कल्प\",\"िष्ठ\",\"जादा\",\"क्कड़\"],     \n",
        "            5: [\"ाएंगी\", \"ाएंगे\", \"ाऊंगी\", \"ाऊंगा\", \"ाइयाँ\", \"ाइयों\", \"ाइयां\", \"अक्कड़\",\"तव्य:\",\"निष्ठ\"],\n",
        "}\n",
        "\n",
        "special_suffixes = [\"र्\", \"ज्य\",\"त्य\"]\n",
        "dict_special_suffixes = {\"र्\":\"ृ\",\n",
        "                         \"ज्य\":\"ज्\",\n",
        "                         \"त्य\":\"त्\"}\n",
        "\n",
        "def hi_stem(word, clean=False,chars=None):\n",
        "    if clean == True:\n",
        "        word = clean_text(word, chars)\n",
        "    \n",
        "    ans = word\n",
        "    bl = False\n",
        "    \n",
        "    if word in words_dict.keys():\n",
        "        return words_dict[word]\n",
        "    \n",
        "    for L in 5, 4, 3, 2, 1:\n",
        "        if len(word) > L + 1:\n",
        "            for suf in suffixes[L]:\n",
        "                if word.endswith(suf):\n",
        "                    ans = word[:-L]\n",
        "                    bl =True\n",
        "        if bl == True:\n",
        "            break\n",
        "                    \n",
        "    if bl == True:\n",
        "        for suf in suffixes[1]:\n",
        "            if ans.endswith(suf): \n",
        "                # use case - गानेवाला\n",
        "                ans = hi_stem(ans)\n",
        "   \n",
        "    for suf in special_suffixes:\n",
        "        if ans.endswith(suf):\n",
        "            l = len(suf)\n",
        "            ans = ans[:-l]\n",
        "            ans += dict_special_suffixes[suf]\n",
        " \n",
        "    return ans\n",
        "\n",
        "def clean_text(text, chars=None):\n",
        "    if chars == None:        \n",
        "        text = re.sub(r\"[()\\\"#/@;:<>{}`+=~|!?,']\", \"\", text)\n",
        "    else:\n",
        "        text = re.sub(r\"[\" +chars+ \"()\\\"#/@;:<>{}`+=~|!?,']\", \"\", text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RggV5hOzULN7"
      },
      "outputs": [],
      "source": [
        "regex_for_english_hindi_emojis=\"[^a-zA-Z#\\U0001F300-\\U0001F5FF'|'\\U0001F600-\\U0001F64F'|'\\U0001F680-\\U0001F6FF'|'\\u2600-\\u26FF\\u2700-\\u27BF\\u0900-\\u097F]\"\n",
        "def clean_tweet(tweet, english_stemmer, stopword):\n",
        "    tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet)\n",
        "    tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', tweet)\n",
        "    tweet = re.sub(regex_for_english_hindi_emojis, ' ', tweet)\n",
        "    tweet = re.sub(\"RT \", \" \", tweet)\n",
        "    tweet = re.sub(\"\\n\", \" \", tweet)\n",
        "    tweet = re.sub(r\" +\", \" \", tweet)\n",
        "    tokens = []\n",
        "    for token in tweet.split():\n",
        "        if token not in stopword:\n",
        "            token = english_stemmer.stem(token)\n",
        "            token = hi_stem(token)\n",
        "            tokens.append(token)\n",
        "    return \" \".join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVJBtGTgo0wb"
      },
      "outputs": [],
      "source": [
        "cleaned_tweets = [clean_tweet(\n",
        "        tweet, english_stemmer, stopword) for tweet in tweets]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1-KFrUEU3Rz"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(min_df = 5)\n",
        "X = vectorizer.fit_transform(cleaned_tweets)\n",
        "X = X.todense()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Subtask_a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "157u8mV0WBIf"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=44)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6ChZAX_sWqt"
      },
      "source": [
        "## Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "jNr0hmq1sUgS",
        "outputId": "e0bec55e-525e-459d-a684-38fdb32cc6bb"
      },
      "outputs": [],
      "source": [
        "classifier =LogisticRegression()\n",
        "classifier.fit(X_train,y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPPwp0K-s1SL"
      },
      "outputs": [],
      "source": [
        "y_pred=classifier.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(classification_report(y_val,y_pred))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classifier Compression (Comparative Analysis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix,f1_score,plot_roc_curve,accuracy_score,roc_curve,roc_auc_score,recall_score,log_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "names = [\n",
        "    \"Nearest Neighbors\",\n",
        "    \"Linear SVM\",\n",
        "    \"RBF SVM\",\n",
        "    \"Gaussian Process\",\n",
        "    \"Decision Tree\",\n",
        "    \"Random Forest\",\n",
        "    \"Neural Net\",\n",
        "    \"AdaBoost\",\n",
        "    \"Naive Bayes\",\n",
        "    \"QDA\",\n",
        "]\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(3),\n",
        "    SVC(kernel=\"linear\", C=0.025),\n",
        "    SVC(gamma=2, C=1),\n",
        "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
        "    DecisionTreeClassifier(max_depth=5),\n",
        "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "    MLPClassifier(alpha=1, max_iter=1000),\n",
        "    AdaBoostClassifier(),\n",
        "    GaussianNB(),\n",
        "    QuadraticDiscriminantAnalysis(),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        " for name, clf in zip(names, classifiers):\n",
        "        clf = make_pipeline(StandardScaler(), clf)\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_pred = clf.predict(X_val)\n",
        "        print(clf)\n",
        "        print(classification_report(y_val, y_pred))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Neural Network model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "y_train=le.fit_transform(y_train)\n",
        "y_val=le.fit_transform(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model=Sequential(\n",
        "    [\n",
        "    Dense(64,activation=\"relu\"),\n",
        "    Dense(32,activation=\"relu\"),\n",
        "    Dense(16,activation=\"relu\"),\n",
        "    Dense(16,activation=\"relu\"),\n",
        "    Dense(8,activation=\"relu\"),\n",
        "    Dense(1,activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile('adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Screenshot 2023-02-20 224048.jpg](attachment:3c8a22bc-af01-4818-957e-3779832394c1.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(X_train, y_train, epochs = 1000, batch_size = 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_val)\n",
        "y_pred = (y_pred > 0.4).astype('int64')\n",
        "y_pred = y_pred.reshape(len(y_pred))    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(classification_report(y_val, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(y_pred,y_val)\n",
        "print('confusion_matrix\\n\\n',cm)\n",
        "print('\\n True Positive(TP)= ',cm[0,0])\n",
        "print('\\n True Negative(TN)= ',cm[1,1]) \n",
        "print('\\n False Positive (FP) = ' , cm[0,1])\n",
        "print('\\n False Negative (FN) = ',cm[1,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# visualization confusion metrix with seaborn metrix\n",
        "\n",
        "import seaborn as sns\n",
        "cm_matrix=pd.DataFrame(data=cm, columns=['Actual Positive :1', 'Actual Negative :0'],\n",
        "                       index=['predict PositiveL:1','Predict Negative :0'])\n",
        "\n",
        "sns.heatmap(cm_matrix, annot =True ,fmt='d',cmap='YlGnBu')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LightGBM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# built the lightgbm model\n",
        "import lightgbm as lgb\n",
        "clf =lgb.LGBMClassifier(boosting_type='dart',class_weight=None,colsample_bytree=1.0,\n",
        "                        importance_type='split',learning_rate=0.1,max_depth=-1,\n",
        "                        min_child_samples=10,min_child_weight=0.001,min_split_gain=0.0,\n",
        "                        n_estimators=10,n_jobs=-1,num_leaves=31,objective='binary',\n",
        "                        random_state=None,reg_alpha=0.0,reg_lambda=0.0,silent=True,\n",
        "                        subsample=1.0,subsample_for_bin=2000,subsample_freq=0,metric='auc',\n",
        "                        )\n",
        "clf.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy =accuracy_score(y_pred,y_val)\n",
        "print('LightGBM Model Accuracy Score : {0:0.8f}'.format(accuracy_score(y_pred,y_val)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred=clf.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Training-set accuracy score: {0:0.8f}'. format(accuracy_score(y_train, y_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred=clf.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print the score on training and test set\n",
        "print('training set score: {:.8}'.format(clf.score(X_train,y_train)))\n",
        "print('Test set score: {:.8f}'.format(clf.score(X_val, y_val)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_pred, y_val)\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
        "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
        "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
        "print('\\nFalse Negatives(FN) = ', cm[1,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# visualize confusion matrix with seaborn heatmap\n",
        "import seaborn as sns\n",
        "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
        "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
        "\n",
        "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# subtask_b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tweets = df_text3.text\n",
        "y = df_text3.labels3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=50)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classifier =LogisticRegression()\n",
        "classifier.fit(X_train,y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred=classifier.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(classification_report(y_val,y_pred))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## classifier comperssion (compartative Analysis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix,f1_score,plot_roc_curve,accuracy_score,roc_curve,roc_auc_score,recall_score,log_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "names = [\n",
        "    \"Nearest Neighbors\",\n",
        "    \"Linear SVM\",\n",
        "    \"RBF SVM\",\n",
        "    \"Gaussian Process\",\n",
        "    \"Decision Tree\",\n",
        "    \"Random Forest\",\n",
        "    \"Neural Net\",\n",
        "    \"AdaBoost\",\n",
        "    \"Naive Bayes\",\n",
        "    \"QDA\",\n",
        "]\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(3),\n",
        "    SVC(kernel=\"linear\", C=0.025),\n",
        "    SVC(gamma=2, C=1),\n",
        "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
        "    DecisionTreeClassifier(max_depth=5),\n",
        "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "    MLPClassifier(alpha=1, max_iter=1000),\n",
        "    AdaBoostClassifier(),\n",
        "    GaussianNB(),\n",
        "    QuadraticDiscriminantAnalysis(),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        " for name, clf in zip(names, classifiers):\n",
        "        clf = make_pipeline(StandardScaler(), clf)\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_pred = clf.predict(X_val)\n",
        "        print(clf)\n",
        "        print(classification_report(y_val, y_pred))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Neural Network Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "y_train=le.fit_transform(y_train)\n",
        "y_val=le.fit_transform(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model=Sequential(\n",
        "    [\n",
        "    Dense(64,activation=\"relu\"),\n",
        "    Dense(32,activation=\"relu\"),\n",
        "    Dense(16,activation=\"relu\"),\n",
        "    Dense(16,activation=\"relu\"),\n",
        "    Dense(8,activation=\"relu\"),\n",
        "    Dense(1,activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile('adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(X_train, y_train, epochs = 1000, batch_size = 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_val)\n",
        "y_pred = (y_pred > 0.4).astype('int64')\n",
        "y_pred = y_pred.reshape(len(y_pred))    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(classification_report(y_val, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(y_pred,y_val)\n",
        "print('confusion_matrix\\n\\n',cm)\n",
        "print('\\n True Positive(TP)= ',cm[0,0])\n",
        "print('\\n True Negative(TN)= ',cm[1,1]) \n",
        "print('\\n False Positive (FP) = ' , cm[0,1])\n",
        "print('\\n False Negative (FN) = ',cm[1,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# visualize confusion matrix with seaborn heatmap\n",
        "import seaborn as sns\n",
        "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'],\n",
        "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
        "\n",
        "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lightgbm model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# built the lightgbm model\n",
        "import lightgbm as lgb\n",
        "clf =lgb.LGBMClassifier(boosting_type='dart',class_weight=None,colsample_bytree=1.0,\n",
        "                        importance_type='split',learning_rate=0.1,max_depth=-1,\n",
        "                        min_child_samples=10,min_child_weight=0.001,min_split_gain=0.0,\n",
        "                        n_estimators=10,n_jobs=-1,num_leaves=31,objective='binary',\n",
        "                        random_state=None,reg_alpha=0.0,reg_lambda=0.0,silent=True,\n",
        "                        subsample=1.0,subsample_for_bin=2000,subsample_freq=0,metric='auc',\n",
        "                        )\n",
        "clf.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy =accuracy_score(y_pred,y_val)\n",
        "print('LightGBM Model Accuracy Score : {0:0.8f}'.format(accuracy_score(y_pred,y_val)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred=clf.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Training-set accuracy score: {0:0.8f}'. format(accuracy_score(y_train, y_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred=clf.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print the score on training and test set\n",
        "print('training set score: {:.8}'.format(clf.score(X_train,y_train)))\n",
        "print('Test set score: {:.8f}'.format(clf.score(X_val, y_val)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_pred, y_val)\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
        "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
        "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
        "print('\\nFalse Negatives(FN) = ', cm[1,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# visualization confusion metrix with seaborn metrix\n",
        "\n",
        "import seaborn as sns\n",
        "cm_matrix=pd.DataFrame(data=cm, columns=['Actual Positive :1', 'Actual Negative :0'],\n",
        "                       index=['predict PositiveL:1','Predict Negative :0'])\n",
        "\n",
        "sns.heatmap(cm_matrix, annot =True ,fmt='d',cmap='YlGnBu')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Subtask_c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tweets = df.text\n",
        "y = df.labels3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=50)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classifier =LogisticRegression()\n",
        "classifier.fit(X_train,y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred=classifier.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(classification_report(y_val,y_pred))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## classifier Compression (Comparative Analysis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix,f1_score,plot_roc_curve,accuracy_score,roc_curve,roc_auc_score,recall_score,log_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "names = [\n",
        "    \"Nearest Neighbors\",\n",
        "    \"Linear SVM\",\n",
        "    \"RBF SVM\",\n",
        "    \"Gaussian Process\",\n",
        "    \"Decision Tree\",\n",
        "    \"Random Forest\",\n",
        "    \"Neural Net\",\n",
        "    \"AdaBoost\",\n",
        "    \"Naive Bayes\",\n",
        "    \"QDA\",\n",
        "]\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(3),\n",
        "    SVC(kernel=\"linear\", C=0.025),\n",
        "    SVC(gamma=2, C=1),\n",
        "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
        "    DecisionTreeClassifier(max_depth=5),\n",
        "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "    MLPClassifier(alpha=1, max_iter=1000),\n",
        "    AdaBoostClassifier(),\n",
        "    GaussianNB(),\n",
        "    QuadraticDiscriminantAnalysis(),\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        " for name, clf in zip(names, classifiers):\n",
        "        clf = make_pipeline(StandardScaler(), clf)\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_pred = clf.predict(X_val)\n",
        "        print(clf)\n",
        "        print(classification_report(y_val, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "le = LabelEncoder()\n",
        "y_train=le.fit_transform(y_train)\n",
        "y_val=le.fit_transform(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model=Sequential(\n",
        "    [\n",
        "    Dense(64,activation=\"relu\"),\n",
        "    Dense(32,activation=\"relu\"),\n",
        "    Dense(16,activation=\"relu\"),\n",
        "    Dense(16,activation=\"relu\"),\n",
        "    Dense(8,activation=\"relu\"),\n",
        "    Dense(1,activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile('adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(X_train, y_train, epochs = 1000, batch_size = 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_val)\n",
        "y_pred = (y_pred > 0.4).astype('int64')\n",
        "y_pred = y_pred.reshape(len(y_pred))    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(classification_report(y_val, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(y_pred,y_val)\n",
        "print('confusion_matrix\\n\\n',cm)\n",
        "print('\\n True Positive(TP)= ',cm[0,0])\n",
        "print('\\n True Negative(TN)= ',cm[1,1]) \n",
        "print('\\n False Positive (FP) = ' , cm[0,1])\n",
        "print('\\n False Negative (FN) = ',cm[1,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# visualization confusion metrix with seaborn metrix\n",
        "\n",
        "import seaborn as sns\n",
        "cm_matrix=pd.DataFrame(data=cm, columns=['Actual Positive :1', 'Actual Negative :0'],\n",
        "                       index=['predict PositiveL:1','Predict Negative :0'])\n",
        "\n",
        "sns.heatmap(cm_matrix, annot =True ,fmt='d',cmap='YlGnBu')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LightGBM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# built the lightgbm model\n",
        "import lightgbm as lgb\n",
        "clf =lgb.LGBMClassifier(boosting_type='dart',class_weight=None,colsample_bytree=1.0,\n",
        "                        importance_type='split',learning_rate=0.1,max_depth=-1,\n",
        "                        min_child_samples=10,min_child_weight=0.001,min_split_gain=0.0,\n",
        "                        n_estimators=10,n_jobs=-1,num_leaves=31,objective='binary',\n",
        "                        random_state=None,reg_alpha=0.0,reg_lambda=0.0,silent=True,\n",
        "                        subsample=1.0,subsample_for_bin=2000,subsample_freq=0,metric='auc',\n",
        "                        )\n",
        "clf.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy =accuracy_score(y_pred,y_val)\n",
        "print('LightGBM Model Accuracy Score : {0:0.8f}'.format(accuracy_score(y_pred,y_val)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred=clf.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Training-set accuracy score: {0:0.8f}'. format(accuracy_score(y_train, y_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred=clf.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print the score on training and test set\n",
        "print('training set score: {:.8}'.format(clf.score(X_train,y_train)))\n",
        "print('Test set score: {:.8f}'.format(clf.score(X_val, y_val)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_pred, y_val)\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
        "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
        "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
        "print('\\nFalse Negatives(FN) = ', cm[1,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# visualization confusion metrix with seaborn metrix\n",
        "\n",
        "import seaborn as sns\n",
        "cm_matrix=pd.DataFrame(data=cm, columns=['Actual Positive :1', 'Actual Negative :0'],\n",
        "                       index=['predict PositiveL:1','Predict Negative :0'])\n",
        "\n",
        "sns.heatmap(cm_matrix, annot =True ,fmt='d',cmap='YlGnBu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
